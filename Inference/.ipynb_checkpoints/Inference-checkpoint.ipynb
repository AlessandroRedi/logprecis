{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc156684-24d9-4f98-a012-beb567b3b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid warnings\n",
    "import warnings\n",
    "import datasets\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "datasets.utils.logging.set_verbosity(datasets.utils.logging.ERROR)\n",
    "datasets.utils.logging.enable_progress_bar()\n",
    "\n",
    "import transformers\n",
    "transformers.utils.logging.set_verbosity(transformers.utils.logging.ERROR)\n",
    "transformers.utils.logging.enable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8814aefc-75f1-4f5d-95ef-e35952c28db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3ec7ddf-77df-4541-bf72-3cd99d070dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e2d8b-939b-4d1a-be9f-8628f7c0a311",
   "metadata": {},
   "source": [
    "### Import big unlabeled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0f987-87f5-48b7-b251-16862221c48f",
   "metadata": {},
   "source": [
    "#### Choose which dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f32cd7-06d3-4f1d-948f-35e62e1c17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Cyberlab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a7ef9a-d8bf-4df3-8b7f-11578a87c843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference corpus contains 771477 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>sessions</th>\n",
       "      <th>indexes_statements_context</th>\n",
       "      <th>order_id</th>\n",
       "      <th>indexes_words_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>enable ; system ; shell ; sh ; cat /proc/mount...</td>\n",
       "      <td>[17, 16, 15, 14]</td>\n",
       "      <td>1</td>\n",
       "      <td>[39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tftp ; wget ; /bin/busybox SAEMW ; dd bs=52 co...</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                                           sessions  \\\n",
       "0           0  enable ; system ; shell ; sh ; cat /proc/mount...   \n",
       "1           0  tftp ; wget ; /bin/busybox SAEMW ; dd bs=52 co...   \n",
       "\n",
       "  indexes_statements_context  order_id  \\\n",
       "0           [17, 16, 15, 14]         1   \n",
       "1               [0, 1, 2, 3]         2   \n",
       "\n",
       "                               indexes_words_context  \n",
       "0  [39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5...  \n",
       "1             [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "inference_corpus = pd.read_csv(f\"../Dataset/Inference/reduced_sessions.csv\")\n",
    "print(f\"Inference corpus contains {inference_corpus.shape[0]} examples\")\n",
    "inference_corpus.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98105398-ad69-4e8d-8a3a-7cbb95a05495",
   "metadata": {},
   "source": [
    "### Obtain tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e1e055-0adc-41ed-b946-59569b988783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 771477/771477 [00:07<00:00, 107143.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>indexes_statements_context</th>\n",
       "      <th>order_id</th>\n",
       "      <th>indexes_words_context</th>\n",
       "      <th>tokenized_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[17, 16, 15, 14]</td>\n",
       "      <td>1</td>\n",
       "      <td>[39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5...</td>\n",
       "      <td>[enable, ;, system, ;, shell, ;, sh, ;, cat, /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]</td>\n",
       "      <td>[tftp, ;, wget, ;, /bin/busybox, SAEMW, ;, dd,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id indexes_statements_context  order_id  \\\n",
       "0           0           [17, 16, 15, 14]         1   \n",
       "1           0               [0, 1, 2, 3]         2   \n",
       "\n",
       "                               indexes_words_context  \\\n",
       "0  [39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5...   \n",
       "1             [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]   \n",
       "\n",
       "                                   tokenized_session  \n",
       "0  [enable, ;, system, ;, shell, ;, sh, ;, cat, /...  \n",
       "1  [tftp, ;, wget, ;, /bin/busybox, SAEMW, ;, dd,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_corpus[\"tokenized_session\"] = inference_corpus[\"sessions\"].progress_apply(lambda sessions: sessions.split(\" \"))\n",
    "inference_corpus.drop(\"sessions\", axis = 1, inplace = True)\n",
    "inference_corpus.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118899b0-3ef7-40a0-a453-9748fdfa5279",
   "metadata": {},
   "source": [
    "### Convert Pandas dataframe to Huggingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e369080b-130f-4bbd-8bd6-3a0ac451ef1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['session_id', 'indexes_statements_context', 'order_id', 'indexes_words_context', 'tokenized_session'],\n",
       "    num_rows: 771477\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "inference_dataset = Dataset.from_pandas(inference_corpus)\n",
    "inference_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e7c9ad-d365-464e-895b-73c65a728cb5",
   "metadata": {},
   "source": [
    "### Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b2daf5-21ae-4ac5-bf03-932d24aed5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Dataset/Training/Supervised/labels.txt\", \"r\") as f:\n",
    "    labels = [el.strip() for el in f.readlines() if el.strip()!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9f343bd-998e-40d9-b5a2-d207055c60ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Execution - Discovery - Persistence - Harmless - Defense Evasion - Impact - Other'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" - \".join(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f782cca-19e7-4b9e-819b-f51ba465ad50",
   "metadata": {},
   "source": [
    "### Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2bbbf30-747b-4dcf-a4d4-a86ce3c4a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Features, Sequence, Value, ClassLabel\n",
    "features = Features(\n",
    "    {\n",
    "        'tokenized_session': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
    "        'indexes_statements_context':  Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
    "        'indexes_words_context':  Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
    "        'session_id': Value(dtype='int32', id=None),\n",
    "        'order_id': Value(dtype='int32', id=None),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "382df421-7889-4dfc-a969-b1e2564987b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ad8a11b3de41fc86d5ec1e806dafbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=63):   0%|          | 0/771477 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ast\n",
    "import multiprocessing\n",
    "# load the dataset and copy the features > \"tokenized_session\": ast.literal_eval(ex[\"tokenized_session\"]),\n",
    "def process(ex):\n",
    "    return {\"tokenized_session\": ex[\"tokenized_session\"], \n",
    "            \"session_id\": int(ex[\"session_id\"]),\n",
    "            \"order_id\": int(ex[\"order_id\"]),\n",
    "            \"indexes_statements_context\": ast.literal_eval(ex[\"indexes_statements_context\"]),\n",
    "            \"indexes_words_context\": ast.literal_eval(ex[\"indexes_words_context\"])\n",
    "           }\n",
    "inference_dataset = inference_dataset.map(process, features=features, num_proc= multiprocessing.cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da43d16-5690-420e-b53f-3c6ac75638f4",
   "metadata": {},
   "source": [
    "#### Create mapping from classes to classes_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a56bb532-0219-420f-9847-df4652973549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Execution',\n",
       " 1: 'Discovery',\n",
       " 2: 'Persistence',\n",
       " 3: 'Harmless',\n",
       " 4: 'Defense Evasion',\n",
       " 5: 'Impact',\n",
       " 6: 'Other'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b50a3-2ee0-44ae-b3d4-022f187b33b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f991b5bb-9538-42ac-b698-105e1542fc40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833a301-5b8f-4156-8889-7da500798e41",
   "metadata": {},
   "source": [
    "### Tokenize dataset\n",
    "#### First give it a shot with larger max size (1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccbbb3a4-1751-4023-ae8f-d6b4ee966468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_context_tokens(context_words, word_ids, input_ids):\n",
    "    tokens_to_keep = []\n",
    "    previous_word = None\n",
    "    for word_id, input_id in zip(word_ids, input_ids):\n",
    "        if word_id is None:\n",
    "            # Special token\n",
    "            tokens_to_keep.append(-100)\n",
    "        elif word_id in context_words:\n",
    "            # Part of context words I don't want to label\n",
    "            tokens_to_keep.append(-100)\n",
    "        elif word_id == previous_word:\n",
    "            # Same word as previous token\n",
    "            tokens_to_keep.append(-100)\n",
    "        else:\n",
    "            # Start of a new word!\n",
    "            previous_word = word_id\n",
    "            tokens_to_keep.append(input_id)\n",
    "    return tokens_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16000cfc-02f8-4386-93ad-e682aeb8b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, max_length):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokenized_session\"], truncation=True, is_split_into_words=True, max_length = max_length\n",
    "    )\n",
    "    indexes_words_context = examples[\"indexes_words_context\"]\n",
    "    context_tokens = []\n",
    "    for it in range(len(examples[\"tokenized_session\"])):\n",
    "        context_words = indexes_words_context[it]\n",
    "        word_ids = tokenized_inputs.word_ids(it)\n",
    "        input_ids = tokenized_inputs.input_ids[it]\n",
    "        context_tokens.append(mask_context_tokens(context_words, word_ids, input_ids))\n",
    "    # Later on, DataCollator will not complain and will pad as input_ids > that is why we kept the name\n",
    "    tokenized_inputs[\"labels\"] = context_tokens\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5740fb05-df14-495e-badf-86accc487984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febfaf1f320042b4912cb5e4b5f90326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=63):   0%|          | 0/771477 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = inference_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=inference_dataset.column_names, \n",
    "    fn_kwargs = {\"max_length\" : 1024},\n",
    "    num_proc= multiprocessing.cpu_count() - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b9d3b7-ea94-433f-b75d-57968eda26f1",
   "metadata": {},
   "source": [
    "#### How many sessions got truncated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da170262-62c7-42f1-b803-2691505d1297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 771477/771477 [02:06<00:00, 6096.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of truncated sessions: 9 (0.00 %)\n",
      "Number of truncated tokens: 1025 (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "truncated_sessions = 0 \n",
    "truncated_tokens = 0\n",
    "all_tokens = 0\n",
    "for it in tqdm(range(inference_dataset.shape[0])):\n",
    "    tokenized_session = tokenized_datasets[it][\"input_ids\"]\n",
    "    n_tokens_session = len(tokenized_session)\n",
    "    if n_tokens_session >= tokenizer.model_max_length:\n",
    "        truncated_sessions += 1\n",
    "        truncated_tokens += (n_tokens_session - tokenizer.model_max_length) \n",
    "    all_tokens += n_tokens_session\n",
    "print(f\"Number of truncated sessions: {truncated_sessions} ({truncated_sessions/inference_dataset.shape[0] * 100:.2f} %)\")\n",
    "print(f\"Number of truncated tokens: {truncated_tokens} ({truncated_tokens/all_tokens * 100:.2f} %)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744983e0-1216-4d84-9d7e-a63ace2a16c6",
   "metadata": {},
   "source": [
    "### Now real tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc4d78cc-781d-49b9-a03c-9c2b8136eb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d7d7ccc6384ad086c2e0cf26a95061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=63):   0%|          | 0/771477 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = inference_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=['indexes_statements_context', 'order_id', 'indexes_words_context', 'tokenized_session'], \n",
    "    fn_kwargs = {\"max_length\" : tokenizer.model_max_length},\n",
    "    num_proc= multiprocessing.cpu_count() - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a741676-2036-4ae6-a6b7-52fc589d915a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Now create DataCollator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc40d7-cd64-4189-96ad-3407d1775483",
   "metadata": {},
   "source": [
    "#### Among others, DataCollator pad all sessions to same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06ba8c4f-9ce2-473f-9ff0-ba176cd3b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359998d-1a21-4e0f-acac-7f5e864d3cd2",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader \n",
    "#### Necessary, since using model that does not have a AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "722cf337-346a-4899-b886-c828e94522ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "inference_dataloader = DataLoader(\n",
    "    tokenized_datasets, collate_fn=data_collator, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f80f1-f8d7-442d-bc1c-1299cbd591ec",
   "metadata": {},
   "source": [
    "### Load the model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9d316c8-1803-47c4-ac34-bc93a8275080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "model_name = \"../Training/Trained_Model/CodeBERT\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    config = model_name + \"config.json\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ef419-0d9e-411c-88ce-afb77ec66c63",
   "metadata": {},
   "source": [
    "### Start the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae3e7af8-e003-4af5-bf29-39377d77fc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 52103/96435 [23:21<22:17, 33.14it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 96435/96435 [44:49<00:00, 35.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44min 42s, sys: 22 s, total: 45min 4s\n",
      "Wall time: 44min 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from tqdm import tqdm\n",
    "model.eval()\n",
    "predictions_list = []\n",
    "logits_list = []\n",
    "session_ids_list = []\n",
    "\n",
    "for local_batch in tqdm(inference_dataloader):\n",
    "    with torch.no_grad():\n",
    "        batch = local_batch.to(device)\n",
    "        session_id = batch[\"session_id\"]\n",
    "        session_id = session_id.reshape(session_id.shape[0], 1)\n",
    "        context_tokens = batch[\"labels\"]\n",
    "        del batch[\"labels\"]\n",
    "        del batch[\"session_id\"]\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    input_ids = batch.input_ids\n",
    "    flatten_input_ids = input_ids.reshape(input_ids.shape[0] * input_ids.shape[1])\n",
    "    flatten_context_tokens = context_tokens.reshape(context_tokens.shape[0] * context_tokens.shape[1])\n",
    "    \"\"\"\n",
    "    Only keeping indexes which are not:\n",
    "    - Special tokens (e.g., start token, end token, ...)\n",
    "    - Context tokens (i.e., the ones we addes for the mitigation policy)\n",
    "    \"\"\"\n",
    "    mask = flatten_context_tokens != -100\n",
    "    #print(f\"At the beginning, session id has shape: {session_id.shape}\")\n",
    "    expanded_session_id = session_id.expand(session_id.shape[0], input_ids.shape[1]).reshape(session_id.shape[0]*input_ids.shape[1])\n",
    "    #print(f\"After the expansion, session id has shape: {expanded_session_id.shape}\")\n",
    "    masked_session_id = expanded_session_id[mask]\n",
    "    logits = outputs.logits\n",
    "    flatten_logits = logits.reshape(logits.shape[0] * logits.shape[1], logits.shape[2])\n",
    "    predicted_logits = flatten_logits[mask].max(dim=-1).values\n",
    "    predictions = flatten_logits[mask].argmax(dim=-1)\n",
    "    #print(f\"After masking, session id has shape: {masked_session_id.shape}\")\n",
    "    #print(f\"Notice that also the predictions has shape: {predictions.shape}\")    \n",
    "    predictions_list += list(predictions.detach().cpu().clone().numpy())\n",
    "    logits_list += list(predicted_logits.detach().cpu().clone().numpy())\n",
    "    session_ids_list += list(masked_session_id.detach().cpu().clone().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d24a4-b1e0-4eb6-a659-6a2368204706",
   "metadata": {},
   "source": [
    "#### Convert to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c230e4e3-40d1-485c-97f3-67e6f5986711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions, logits, sessions_ids = np.array(predictions_list), np.array(logits_list), np.array(session_ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd604e-a2ed-49a7-8c41-1d095b77f5fd",
   "metadata": {},
   "source": [
    "### Import thresholds\n",
    "#### we trained on 5 seeds -> average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b0f694c-d1c2-470b-91c6-54c1df35255e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>lower_interval</th>\n",
       "      <th>upper_interval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Execution</th>\n",
       "      <td>0.570615</td>\n",
       "      <td>0.509742</td>\n",
       "      <td>0.631488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discovery</th>\n",
       "      <td>0.604162</td>\n",
       "      <td>0.496116</td>\n",
       "      <td>0.712208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean  lower_interval  upper_interval\n",
       "Class                                              \n",
       "Execution  0.570615        0.509742        0.631488\n",
       "Discovery  0.604162        0.496116        0.712208"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thresholds = pd.read_csv(\"../Training/Trained_Model/thresholds.csv\").rename({\"Unnamed: 0\":\"Class\"}, axis = 1)\n",
    "df_thresholds.set_index('Class', inplace=True)\n",
    "df_thresholds.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd3c70f-7365-4201-945f-eec56416bf61",
   "metadata": {},
   "source": [
    "#### Import min max scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d142354-5466-4d9f-ac7c-9218ffc17dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_max = pd.read_csv(\"../Training/Trained_Model/min_max_scaler.csv\")\n",
    "min_training_logits = df_min_max[\"min_training_logits\"].iloc[0]\n",
    "max_training_logits = df_min_max[\"max_training_logits\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1fcc920-ec68-4e9c-bb2e-65ddd3c731a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We made 28151440 predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Session_ids</th>\n",
       "      <th>Logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.045496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.975620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictions  Session_ids    Logits\n",
       "0            1            0  7.045496\n",
       "1            1            0  6.975620"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_output = pd.DataFrame(list(zip(predictions, sessions_ids, logits)), columns =['Predictions', 'Session_ids', 'Logits'])\n",
    "print(f\"We made {df_model_output.shape[0]} predictions\")\n",
    "df_model_output.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07b649cc-96bd-4b79-b648-36934fb599c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28151440/28151440 [20:16<00:00, 23135.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Session_ids</th>\n",
       "      <th>Logits</th>\n",
       "      <th>new_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.045496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.975620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.038234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.960073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.041942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictions  Session_ids    Logits  new_predictions\n",
       "0            1            0  7.045496                1\n",
       "1            1            0  6.975620                1\n",
       "2            1            0  7.038234                1\n",
       "3            1            0  6.960073                1\n",
       "4            1            0  7.041942                1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_threshold(prediction, logit):\n",
    "    normalized_logit = (logit - min_training_logits)/ max_training_logits\n",
    "    if normalized_logit >= df_thresholds.loc[id2label[prediction]][\"mean\"]: \n",
    "        return int(prediction)\n",
    "    else:\n",
    "        return 10\n",
    "df_model_output[\"new_predictions\"] = df_model_output.progress_apply(lambda row: check_threshold(row.Predictions, row.Logits), axis = 1) \n",
    "df_model_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f570249e-f493-4806-a456-0528adf2b311",
   "metadata": {},
   "source": [
    "### Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7560d1e8-76f3-495a-970c-9085c4f38a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7bfeb4f-6d81-484c-8083-04957c75fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_output.to_csv(f\"./predictions.csv\", index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8f9181b-e5cb-4f63-a40c-14c2d9e7592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_corpus[[\"session_id\", \"order_id\", \"tokenized_session\"]].to_csv(f\"./to_join_with_predictions.csv\", index=False, quoting=csv.QUOTE_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mboffa-cuda]",
   "language": "python",
   "name": "conda-env-mboffa-cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
