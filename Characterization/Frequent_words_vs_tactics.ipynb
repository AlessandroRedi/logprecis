{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776353ce-ac75-4ee2-86a6-7b2bb2faf02f",
   "metadata": {},
   "source": [
    "# This notebook prepare some examples to:\n",
    "- Create a table to visualize most frequent words vs their predictions\n",
    "- Prove the importance of Attention ('echo' and 'rm' examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8678c5e3-00bd-4625-bc8d-87c8b5d356ff",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896f3c0-0082-491f-81aa-2252241e3938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6826285b-f735-4b1f-959a-fe28e6f14301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "predicted_corpus = pd.read_csv(f\"../Inference/corpus_with_predictions.csv\")\n",
    "print(f\"Corpus contains {predicted_corpus.shape[0]} unique sessions and {predicted_corpus.Models_predictions.nunique()} unique sequences of predictions\")\n",
    "predicted_corpus.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e0e2d-5c0a-494d-9b8d-ea1c0083ebd1",
   "metadata": {},
   "source": [
    "#### Filter \"/system scheduler\" sessions --> not bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7bd82e-4707-43fb-996c-155ba59a6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before filtering '/system scheduler' sessions: {predicted_corpus.shape[0]}\")\n",
    "predicted_corpus = predicted_corpus[~predicted_corpus.full_session.str.contains(\"/system scheduler\")]\n",
    "print(f\"After filtering '/system scheduler' sessions: {predicted_corpus.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e2839-f615-4dbd-95ec-390e1a9c2ede",
   "metadata": {},
   "source": [
    "#### Create date attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501d213-f130-48b1-a649-d1fe35dd8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_corpus[\"first_timestamp\"] = pd.to_datetime(predicted_corpus[\"first_timestamp\"])\n",
    "predicted_corpus[\"date\"] = predicted_corpus[\"first_timestamp\"].apply(lambda datetime: datetime.date())\n",
    "predicted_corpus.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cfca76-09a2-4d91-b01d-efc65e3575fd",
   "metadata": {},
   "source": [
    "#### Plot distribution of intents over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f2a5c-5439-42d3-9748-827b8b8c8762",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_date_predictions = predicted_corpus[[\"full_session\", \"Models_predictions\", \"date\"]]\n",
    "sessions_date_predictions[\"splitted_session\"] = sessions_date_predictions[\"full_session\"].apply(lambda session: session.split(\" \"))\n",
    "sessions_date_predictions[\"splitted_prediction\"] = sessions_date_predictions[\"Models_predictions\"].apply(lambda predictions: predictions.split(\" -- \"))\n",
    "exploded_df = sessions_date_predictions[[\"splitted_session\", \"splitted_prediction\", \"date\"]].explode([\"splitted_session\", \"splitted_prediction\"])\n",
    "print(f\"Exploded dataset contains {exploded_df.shape[0]} rows and {exploded_df.shape[1]} columns\")\n",
    "exploded_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d2bdd-bbe1-4112-a431-efa561a9ad22",
   "metadata": {},
   "source": [
    "##### Groupby date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1d323-de43-4773-8e50-d04439f3b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences_x_day = exploded_df.groupby([\"date\", \"splitted_prediction\"]).size().reset_index(name = \"daily_occurrences\")\n",
    "occurrences_x_day.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ca105-3775-4699-91b7-4f0d603e7319",
   "metadata": {},
   "source": [
    "##### Calculate CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e0e4d-d9b9-4867-a270-5800589b14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences_x_day[\"cumulative_occurrences\"] = occurrences_x_day.groupby(['splitted_prediction'])['daily_occurrences'].cumsum()\n",
    "occurrences_x_day = occurrences_x_day.merge(occurrences_x_day.groupby(\"splitted_prediction\")[\"daily_occurrences\"].sum().reset_index(name = \"tot_occurrences\"), on = \"splitted_prediction\")\n",
    "occurrences_x_day[\"cdf\"] = occurrences_x_day.apply(lambda row: row[\"cumulative_occurrences\"] / row[\"tot_occurrences\"], axis = 1)\n",
    "occurrences_x_day.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb5c7a-9429-4e10-928b-b0c41b5743e0",
   "metadata": {},
   "source": [
    "#### Create colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39d873-b847-4965-9e0d-fe478579fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "bars = occurrences_x_day.drop_duplicates(\"splitted_prediction\").sort_values(by = \"tot_occurrences\", ascending = False)\n",
    "palette = sns.color_palette(\"bright\", bars.splitted_prediction.nunique())\n",
    "role2color = {color:prediction for color, prediction in zip(bars.splitted_prediction.unique(), palette)}\n",
    "hex_role2color = {color:prediction for color, prediction in zip(bars.splitted_prediction.unique(), palette.as_hex())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a720ebda-0a18-4606-83a5-0a29eabe11c9",
   "metadata": {},
   "source": [
    "#### How many words per class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac3f14-d31c-464f-92d1-1bfaa7a4e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_per_class = bars[[\"splitted_prediction\", \"tot_occurrences\"]]\n",
    "prediction_per_class[\"%_over_corpus\"] = prediction_per_class[\"tot_occurrences\"].apply(lambda occ: round(occ / prediction_per_class.tot_occurrences.sum() * 100, 3))\n",
    "prediction_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18afa8bf-6798-49dc-8a5a-a146f84abfa5",
   "metadata": {},
   "source": [
    "#### How many words in general?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1154c11-0360-4742-a163-5edb63c8972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_per_class.tot_occurrences.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d7e3a-a303-49cb-8ce0-8db81a1bacc8",
   "metadata": {},
   "source": [
    "#### Given Discovery, what's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a95e7-32cf-4d26-bb97-390bb87cc601",
   "metadata": {},
   "source": [
    "##### Obtain set of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb0ac6f-852a-4ad0-98ed-053e15ec6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetitions(fingreprint):\n",
    "    list_elements = fingreprint.split(\" -- \")\n",
    "    prev_el = list_elements[0]\n",
    "    non_repeated_list = []\n",
    "    for it in range(1,len(list_elements)):\n",
    "        el = list_elements[it]\n",
    "        if prev_el != el:\n",
    "            non_repeated_list.append(str(prev_el))\n",
    "            prev_el = el\n",
    "    non_repeated_list.append(str(prev_el))        \n",
    "    return \" -- \".join(non_repeated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c67cf-7c7f-411c-9e1c-53fd122fda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_corpus[\"set_tactics\"] = predicted_corpus[\"Models_predictions\"].progress_apply(lambda predictions_list: remove_repetitions(predictions_list))\n",
    "predicted_corpus.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98321e14-914a-44a3-8f3a-5f98b93902f8",
   "metadata": {},
   "source": [
    "##### Now, for each session, we want to create the origin/destination matrix\n",
    "###### Each session will get a |classes| x |classes| matrix (which we'll then convert to a flat tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c689f-78ef-4d30-bbb3-1954d0b39457",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_with_discovery = predicted_corpus[predicted_corpus.Predicted_classes.str.contains(\"Discovery\")]\n",
    "sessions_with_discovery.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808116ba-0f95-4e4c-b8eb-5b4ef6e5725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "destinations_discovery = {\"Stop\":0}\n",
    "change_transition = 0\n",
    "def count_destinations_from_discovery(predictions, destinations_discovery):\n",
    "    change_transition = 0\n",
    "    if predictions.strip() == \"Discovery\":\n",
    "        destinations_discovery[\"Stop\"] += 1\n",
    "    origins = predictions.split(\" -- \")[:-1]\n",
    "    destinations = predictions.split(\" -- \")[1:]\n",
    "    for it, el in enumerate(origins):\n",
    "        if el == \"Discovery\":\n",
    "            change_transition += 1\n",
    "            destination = destinations[it]\n",
    "            if destination not in  destinations_discovery.keys():\n",
    "                destinations_discovery[destination] = 0\n",
    "            destinations_discovery[destination] += 1\n",
    "    return change_transition\n",
    "for set_tactics in predicted_corpus[\"set_tactics\"]:\n",
    "    change_transition += count_destinations_from_discovery(set_tactics, destinations_discovery)\n",
    "change_transition, destinations_discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586fd20-b1f0-482c-9944-7a9842bd2b08",
   "metadata": {},
   "source": [
    "#### Fill missing dates with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db233e21-e4cc-4836-9df2-bdcc35c2ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cdfs(cdf, dates):\n",
    "    cdf = cdf.copy().set_index(\"date\")\n",
    "    cdf.index = pd.DatetimeIndex(cdf.index)\n",
    "    cdf = cdf.reindex(dates, method = 'ffill') #Every prediction must be equally indexed: if no improvements that day, put last valid value\n",
    "    return cdf.asfreq('D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5351f9-36ae-46c1-9619-f25b00aea17d",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e17f15-9b69-4211-9c2b-fd92c94a2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = occurrences_x_day.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83ddcb-4331-4842-ac04-6d8bf1c14d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, axs = plt.subplots(1,2, figsize =(12, 3))\n",
    "fontsize = 15\n",
    "#Axis 1\n",
    "sns.barplot(data=bars, x=\"tot_occurrences\", y =\"splitted_prediction\", hue = \"splitted_prediction\", dodge = False, palette = role2color, ax = axs[0])\n",
    "axs[0].legend_.remove()\n",
    "axs[0].set_xlabel('|Words per prediction|', fontsize = fontsize)\n",
    "axs[0].set_ylabel(\"\")\n",
    "axs[0].set_xscale(\"log\")\n",
    "axs[0].xaxis.set_tick_params(labelsize=fontsize)\n",
    "axs[0].yaxis.set_tick_params(labelsize=fontsize)\n",
    "axs[0].grid()\n",
    "#Axis 2\n",
    "\n",
    "for role in occurrences_x_day.splitted_prediction.unique():\n",
    "    cdf = occurrences_x_day[occurrences_x_day.splitted_prediction == role][[\"date\", \"cdf\"]]\n",
    "    cdf = plot_cdfs(cdf, dates)\n",
    "    axs[1].plot(cdf.index, cdf.cdf, color = role2color[role], linewidth = 3)\n",
    "    \n",
    "#sns.lineplot(data=occurrences_x_day, x=\"date\", y =\"cdf\", hue = \"splitted_prediction\", palette = role2color, ax = axs[1], linewidth = 3)\n",
    "\n",
    "axs[1].set_xlabel('Date', fontsize = fontsize)\n",
    "axs[1].set_ylabel('ECDF of prediction', fontsize = fontsize)\n",
    "axs[1].yaxis.set_tick_params(labelsize=fontsize)\n",
    "axs[1].xaxis.set_tick_params(labelsize=fontsize, rotation = 30)\n",
    "axs[1].grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./Inference_results/1_Stats_per_prediction/{dataset}_predictions_stats.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b461056-aa94-4a07-9922-49486e7e899a",
   "metadata": {},
   "source": [
    "#### Now, I want to know the predictions assigned per words\n",
    "##### We will study:\n",
    "- Given a prediction, which is the word assigned to that prediction for more time\n",
    "- Given a word (more frequent ones), which is their prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1180db02-329c-4994-b694-3d4c7dc49f95",
   "metadata": {},
   "source": [
    "#### Keep only 1st session per sequence of intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e42edd-a13c-44fe-a5f3-1d78d45b5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_corpus = predicted_corpus.sort_values(by = \"date\").drop_duplicates([\"Models_predictions\"])\n",
    "print(f\"Selected {unique_corpus.shape[0]} rows\")\n",
    "unique_corpus.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9699fc-a827-4dc9-99d5-b605d5cd55e6",
   "metadata": {},
   "source": [
    "##### Explode dataset, so that each row contains a word and a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf31c33-6f6b-4017-abd8-a61e0ad85328",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_corpus[\"splitted_session\"] = unique_corpus[\"full_session\"].apply(lambda session: session.split(\" \"))\n",
    "unique_corpus[\"splitted_prediction\"] = unique_corpus[\"Models_predictions\"].apply(lambda predictions: predictions.split(\" -- \"))\n",
    "exploded_df = unique_corpus[[\"splitted_session\", \"splitted_prediction\", \"date\"]].explode([\"splitted_session\", \"splitted_prediction\"])\n",
    "print(f\"Exploded dataset contains {exploded_df.shape[0]} rows and {exploded_df.shape[1]} columns\")\n",
    "exploded_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85879691-db9d-4036-8bca-db5d003d343f",
   "metadata": {},
   "source": [
    "##### Count how many unique tuples (\"word\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c4644-b2aa-4a00-8938-d8150f065334",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = exploded_df.groupby([\"splitted_session\", \"splitted_prediction\"]).size().reset_index(name = \"occurrences_tuple\")\n",
    "print(f\"The dataset contains {grouped_df.shape[0]} unique tuples\")\n",
    "grouped_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748226a6-3662-47fd-8691-c4a54126b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Particularly, it contains {grouped_df.splitted_session.nunique()} unique words and {grouped_df.splitted_prediction.nunique()} unique predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cc70d-c89f-4e8a-afff-81ff0251f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cdf_tuples_occurrences = grouped_df.value_counts(\"occurrences_tuple\").sort_index()\n",
    "cdf_tuples_occurrences = np.cumsum(cdf_tuples_occurrences)/np.sum(cdf_tuples_occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc77244-26dd-4b53-8eab-e9ea94d3c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig, axs = plt.subplots(1, figsize=(4,3))\n",
    "fontsize = 18\n",
    "axs.plot(cdf_tuples_occurrences.reset_index()[\"occurrences_tuple\"], cdf_tuples_occurrences.reset_index()[0], linewidth = 2)\n",
    "axs.set_xlabel('|occurrences| (Word, Prediction)', fontsize = fontsize + 3)\n",
    "axs.set_xscale(\"log\")\n",
    "axs.set_ylabel('ECDF', fontsize = fontsize)\n",
    "axs.set_xticks([1, 10, 100, 1_000, 10_000])\n",
    "axs.yaxis.set_tick_params(labelsize=fontsize)\n",
    "axs.xaxis.set_tick_params(labelsize=fontsize)\n",
    "axs.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6d8ae-c30d-4f7d-a2ff-e8f576b7af80",
   "metadata": {},
   "source": [
    "##### Now group by word and collect:\n",
    "- list of assigned predictions\n",
    "- occurrences of that word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08426a14-9a51-4b47-8e2f-48a04d780728",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_word = exploded_df.groupby(\"splitted_session\").agg({\"splitted_prediction\":list, \"date\":\"count\"}).rename({\"splitted_prediction\":\"assigned_predictions\", \"date\":\"word_occurrences\"}, axis = 1)\n",
    "print(f\"Dataset contains {groupby_word.shape[0]} unique words\")\n",
    "groupby_word.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7552e7bc-26dd-4dc0-8e55-0ef5db9f14a2",
   "metadata": {},
   "source": [
    "###### Trick to easily count labels occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9edcf5c-a965-4184-8077-a820518bb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_word[\"assigned_predictions\"] = groupby_word[\"assigned_predictions\"].apply(lambda list_predictions: \" __ \".join(list_predictions))\n",
    "groupby_word.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9802b-3465-40ab-ac4c-ded1721745a5",
   "metadata": {},
   "source": [
    "###### Doing that, each row will contain dates. Each column will be associated to a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240abb3-16c0-4dda-8bf3-7c524cd52ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(session):\n",
    "    return [el.strip() for el in session.split(\" __ \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630da5a8-eaa3-4983-9443-6c162daef72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(tokenizer=custom_tokenizer, lowercase = False)\n",
    "X = vectorizer.fit_transform(groupby_word.assigned_predictions).toarray()\n",
    "names = vectorizer.get_feature_names_out()\n",
    "df_count_vectorizer = pd.DataFrame(X, columns=names)\n",
    "print(f\"Dataframe has shape {df_count_vectorizer.shape[0]} x {df_count_vectorizer.shape[1]}\")\n",
    "df_count_vectorizer.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a99a8-af50-4a14-8f08-4ac18fb6b7aa",
   "metadata": {},
   "source": [
    "##### Concat two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccce9ba-f79e-4ff1-b125-1d603763f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([groupby_word.reset_index(), df_count_vectorizer.reset_index(drop = True)], axis = 1)\n",
    "concat_df.sort_values(by = \"word_occurrences\", ascending = False, inplace = True)\n",
    "concat_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69658ad8-46f3-4b18-a1f1-bcc85edfa393",
   "metadata": {},
   "source": [
    "##### Visualize top-10 words\n",
    "##### Keep only words with alphas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96e80a-f7da-491d-af85-b16edc7ed1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "to_plot_df = concat_df.copy()\n",
    "to_plot_df[\"is_alpha\"] = to_plot_df[\"splitted_session\"].apply(lambda word: False if re.search('[a-zA-Z]', word) == None else True)\n",
    "to_plot_df[\"is_flag\"] = to_plot_df[\"splitted_session\"].apply(lambda word: \"-\" in word)\n",
    "\n",
    "top = to_plot_df[(to_plot_df.is_alpha == True) & (to_plot_df.is_flag == False)].iloc[:20]\n",
    "top = top[[\"splitted_session\"] + list(top.columns[-9:-2].values)]\n",
    "top.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe840e-d4c0-43bb-9b71-4f95b773000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "top[top.columns[1:]] = top.apply(lambda row: row[1:] / np.sum(row[1:]), axis = 1)\n",
    "top[\"entropy\"] = top.apply(lambda row: entropy(row[1:].astype(float), base=2), axis = 1)\n",
    "top.sort_values(by = \"entropy\", inplace = True)\n",
    "top.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf4402a-ac80-4e66-8d29-328f89b35757",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, figsize =(17, 6))\n",
    "fontsize = 10\n",
    "#First matrix\n",
    "data_values = top.T.loc[top.columns[1:-1]].astype(\"float\")\n",
    "normed_data_values=data_values.apply(lambda column: column / column.sum(), axis=0)\n",
    "\n",
    "im = sns.heatmap(normed_data_values, linewidth = 0.1, cmap=\"jet\", ax = axs, annot = True, annot_kws={\"fontsize\":fontsize}, fmt='.2f', cbar_kws={\"orientation\": \"horizontal\", \"location\":\"top\"})\n",
    "\n",
    "axs.set_xticklabels(top.T.loc[\"splitted_session\"], fontsize = fontsize + 2, rotation = 90)\n",
    "axs.set_yticklabels(top.columns[1:-1], fontsize = fontsize + 2, rotation = 0)\n",
    "cbar = axs.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./Inference_results/word_vs_prediction.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9a86f-694a-461a-818d-84ff81c72497",
   "metadata": {},
   "source": [
    "## STUDY ON ECHO - Go simple here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec0116-03c8-4903-b7f3-4e32a860ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before filtering: {predicted_corpus.shape[0]} (and {predicted_corpus.Models_predictions.nunique()} families)\")\n",
    "df_echo= predicted_corpus[predicted_corpus.full_session.str.contains(\" echo\")]\n",
    "print(f\"Sessions containing 'echo': {df_echo.shape[0]} (and {df_echo.Models_predictions.nunique()} families)\")\n",
    "df_echo.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7504552-8dee-4592-bc7c-55082018ed53",
   "metadata": {},
   "source": [
    "#### Now keep track of the predictions we associated to 'echo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2894f318-2690-4efb-b23b-ed9ba6a6e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_echo(session, predictions):\n",
    "    echo_roles = []\n",
    "    words = session.split(\" \")\n",
    "    predictions = predictions.split(\" -- \")\n",
    "    for word, prediction in zip(words, predictions):\n",
    "        if \"echo\" == word:\n",
    "            echo_roles.append(prediction)\n",
    "    return \" -- \".join(echo_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba535da-a508-4320-8e09-fe7c94b5dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df_echo[\"echo_roles\"] = df_echo.progress_apply(lambda row: track_echo(row.full_session, row.Models_predictions), axis = 1)\n",
    "df_echo.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa1dea-040a-4267-b917-02a33638c3ef",
   "metadata": {},
   "source": [
    "### How many sessions we can associate to each echo's use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b61a4-6e3f-4c8f-aca4-e9c4aa513648",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_associated_to_use = df_echo.groupby(\"echo_roles\").full_session.count().reset_index(name = \"associated_sessions\")\n",
    "print(f\"There are {sessions_associated_to_use.shape[0]} different uses of the command 'echo'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d790fe-b6bf-4300-baee-666b5c60b9ee",
   "metadata": {},
   "source": [
    "### Count how many \"families\" we associated per use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ba157-7af8-4d96-8f98-a0c79777bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "families_associated_to_use = df_echo.drop_duplicates(\"Models_predictions\").groupby(\"echo_roles\").Models_predictions.count().reset_index(name = \"associated_families\")\n",
    "sessions_and_families_per_use = sessions_associated_to_use.merge(families_associated_to_use, on = \"echo_roles\")\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(sessions_and_families_per_use.sort_values(by = \"associated_sessions\", ascending = False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e45a0-7fb0-4362-b01f-103fe4b3a70d",
   "metadata": {},
   "source": [
    "#### Show some examples of such usages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc13ad-717b-4c15-8a71-9f3f22da7ff0",
   "metadata": {},
   "source": [
    "##### Idea is to select a family associated to role if:\n",
    "- Family is numerous enough \n",
    "- Family is \"dissimilar\" to the ones observed before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7055d1da-f9bb-4680-9fc1-4bcaa7c3a5bb",
   "metadata": {},
   "source": [
    "##### Create OneHotEncoded versions of inputs\n",
    "###### so that we can compute word level levenstein and print \"different\" families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6eb06-d97f-4f4b-a925-4bf67faa9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Dataset/Training/Supervised/labels.txt\", \"r\") as f:\n",
    "    labels = [el.strip() for el in f.readlines()]\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39596e-0468-4ee0-b146-dd400d7acded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_echo.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0d587c-3320-4942-ba7c-389c8c866cbb",
   "metadata": {},
   "source": [
    "##### Function to color items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe92b3-bbfb-41ec-8d10-da9a0de1e8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def color_sessions(session, not_confident_predictions, models_predictions, chosen_word):\n",
    "    words = session.split(\" \") \n",
    "    not_confident_predictions = not_confident_predictions.split(\" -- \") \n",
    "    models_predictions = models_predictions.split(\" -- \") \n",
    "    new_words = []\n",
    "    for word, prediction, model_prediction in zip(words, not_confident_predictions, models_predictions):\n",
    "        if word == chosen_word:\n",
    "            new_word = f'<u><b><span style=\"color:{hex_role2color[model_prediction]};\"> {word}</span></b></u>'\n",
    "        else:\n",
    "            new_word = f'<span style=\"color:{hex_role2color[model_prediction]};\"> {word}</span>'\n",
    "        new_words.append(new_word)\n",
    "    return \" \".join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3709055-187a-4302-8145-ea9df77729d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetitions(sequence_intents):\n",
    "    list_elements = sequence_intents.split(\" -- \")\n",
    "    prev_el = list_elements[0]\n",
    "    non_repeated_list = []\n",
    "    counter = 1\n",
    "    for it in range(1,len(list_elements)):\n",
    "        el = list_elements[it]\n",
    "        if prev_el != el:\n",
    "            non_repeated_list.append(f\"{prev_el} x {counter}\")\n",
    "            counter = 1\n",
    "            prev_el = el\n",
    "        else:\n",
    "            counter += 1\n",
    "    # For last element\n",
    "    non_repeated_list.append(f\"{prev_el} x {counter}\")        \n",
    "    return \" -- \".join(non_repeated_list)\n",
    "\n",
    "def color_roles(models_predictions):\n",
    "    non_repeated_roles = remove_repetitions(models_predictions)\n",
    "    new_words = []\n",
    "    for role_and_counter in non_repeated_roles.split(\" -- \"):\n",
    "        role = role_and_counter.split(\" x \")[0]\n",
    "        new_words.append(f'<span style=\"color:{hex_role2color[role]};\"> {role_and_counter}</span>')\n",
    "    return \" \".join(new_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c6422b-8ff0-4fb7-9db1-f77a1e860fa6",
   "metadata": {},
   "source": [
    "##### Sort previous dataframe according to number of associated sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb17b3-4744-41a3-b82d-f503e9115225",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_and_families_per_use.sort_values(by = \"associated_sessions\", ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06f2b9-787e-44bd-95dc-00a504a4ebac",
   "metadata": {},
   "source": [
    "##### Create DF to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfbbf3-c8cf-489b-adce-628e0f703c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_echo_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df48d427-20ab-4a8a-b758-9dac68474362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as lev\n",
    "\n",
    "selected_role = sessions_and_families_per_use.echo_roles.iloc[0]\n",
    "print(f\"For echo roles: {selected_role}\")\n",
    "examples = df_echo[df_echo.echo_roles == selected_role]\n",
    "families_numerosities = examples.groupby(\"Models_predictions\").full_session.count().reset_index(name = \"occurrences\").sort_values(by = \"occurrences\", ascending = False)\n",
    "prev_families = [\"\"]\n",
    "it = 0\n",
    "i = 0\n",
    "while i < 3 and it != families_numerosities.shape[0]: # for the top 3 families\n",
    "    chosen_family = families_numerosities.iloc[it].Models_predictions\n",
    "    nc_prediction = df_echo[df_echo.Models_predictions == chosen_family].Predicted_classes.iloc[0]\n",
    "    occurrences = families_numerosities.iloc[it].occurrences\n",
    "    embedded_family = \"\".join([str(label2id[word]) for word in chosen_family.split(\" -- \")])\n",
    "    flag = True\n",
    "    for prev_family in prev_families: # Check the examples you showed before. Accept new examples if \"dissimilar\" enough\n",
    "        lev_distance = lev(prev_family, embedded_family)\n",
    "        if lev_distance < 5: #At least 5 words must be different\n",
    "            flag = False\n",
    "    if flag:\n",
    "        examples_for_family = examples[examples.Models_predictions == chosen_family][\"full_session\"]\n",
    "        for it in range(np.min([2, examples_for_family.shape[0]])):\n",
    "            full_session = examples_for_family.iloc[it]\n",
    "            colored_sessions = color_sessions(full_session, nc_prediction, chosen_family, \"echo\")\n",
    "            colored_roles = color_roles(chosen_family)\n",
    "            df_echo_results.append((colored_roles, colored_sessions))\n",
    "        prev_families.append(embedded_family)\n",
    "        i += 1\n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72132ee6-70d1-4ada-bff5-e5cefacf8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as lev\n",
    "\n",
    "selected_role = sessions_and_families_per_use.echo_roles.iloc[3]\n",
    "print(f\"For echo roles: {selected_role}\")\n",
    "examples = df_echo[df_echo.echo_roles == selected_role]\n",
    "families_numerosities = examples.groupby(\"Models_predictions\").full_session.count().reset_index(name = \"occurrences\").sort_values(by = \"occurrences\", ascending = False)\n",
    "prev_families = [\"\"]\n",
    "it = 0\n",
    "i = 0\n",
    "while i < 3 and it != families_numerosities.shape[0]: # for the top 3 families\n",
    "    chosen_family = families_numerosities.iloc[it].Models_predictions\n",
    "    nc_prediction = df_echo[df_echo.Models_predictions == chosen_family].Predicted_classes.iloc[0]\n",
    "    occurrences = families_numerosities.iloc[it].occurrences\n",
    "    embedded_family = \"\".join([str(label2id[word]) for word in chosen_family.split(\" -- \")])\n",
    "    flag = True\n",
    "    for prev_family in prev_families: # Check the examples you showed before. Accept new examples if \"dissimilar\" enough\n",
    "        lev_distance = lev(prev_family, embedded_family)\n",
    "        if lev_distance < 5: #At least 5 words must be different\n",
    "            flag = False\n",
    "    if flag:\n",
    "        examples_for_family = examples[examples.Models_predictions == chosen_family][\"full_session\"]\n",
    "        for it in range(np.min([2, examples_for_family.shape[0]])):\n",
    "            full_session = examples_for_family.iloc[it]\n",
    "            colored_sessions = color_sessions(full_session, nc_prediction, chosen_family,\"echo\")\n",
    "            colored_roles = color_roles(chosen_family)\n",
    "            df_echo_results.append((colored_roles, colored_sessions))\n",
    "        prev_families.append(embedded_family)\n",
    "        i += 1\n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f3ffc-4754-43ad-8bd1-e2f0b3874261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as lev\n",
    "\n",
    "selected_role = sessions_and_families_per_use.echo_roles.iloc[2]\n",
    "print(f\"For echo roles: {selected_role}\")\n",
    "examples = df_echo[df_echo.echo_roles == selected_role]\n",
    "families_numerosities = examples.groupby(\"Models_predictions\").full_session.count().reset_index(name = \"occurrences\").sort_values(by = \"occurrences\", ascending = False)\n",
    "prev_families = [\"\"]\n",
    "it = 0\n",
    "i = 0\n",
    "while i < 3 and it != families_numerosities.shape[0]: # for the top 3 families\n",
    "    chosen_family = families_numerosities.iloc[it].Models_predictions\n",
    "    nc_prediction = df_echo[df_echo.Models_predictions == chosen_family].Predicted_classes.iloc[0]\n",
    "    occurrences = families_numerosities.iloc[it].occurrences\n",
    "    embedded_family = \"\".join([str(label2id[word]) for word in chosen_family.split(\" -- \")])\n",
    "    flag = True\n",
    "    for prev_family in prev_families: # Check the examples you showed before. Accept new examples if \"dissimilar\" enough\n",
    "        lev_distance = lev(prev_family, embedded_family)\n",
    "        if lev_distance < 5: #At least 5 words must be different\n",
    "            flag = False\n",
    "    if flag:\n",
    "        examples_for_family = examples[examples.Models_predictions == chosen_family][\"full_session\"]\n",
    "        for it in range(np.min([2, examples_for_family.shape[0]])):\n",
    "            full_session = examples_for_family.iloc[it]\n",
    "            colored_sessions = color_sessions(full_session, nc_prediction, chosen_family, \"echo\")\n",
    "            colored_roles = color_roles(chosen_family)\n",
    "            df_echo_results.append((colored_roles, colored_sessions))\n",
    "        prev_families.append(embedded_family)\n",
    "        i += 1\n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6693eb74-ca42-455c-ba56-94c595017449",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970dc70e-4233-4a4c-9105-c16a2bed779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_export = pd.DataFrame(df_echo_results, columns = [\"Sequence of intents\", \"Session\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112fa153-8f4d-455a-b02b-ddc6d61b7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_export.to_html(f\"./Inference_results/1_Stats_per_prediction/{dataset}_echo_study.html\", escape = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10acc975-d108-4c45-9d2d-191f75671c05",
   "metadata": {},
   "source": [
    "## STUDY ON RM - Bit harder, to show that the problem is non-trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c3e5e-a3a7-4063-b5db-31f66a29ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before filtering: {predicted_corpus.shape[0]} (and {predicted_corpus.Models_predictions.nunique()} families)\")\n",
    "df_rm = predicted_corpus[predicted_corpus.full_session.str.contains(\" rm\")]\n",
    "print(f\"Sessions containing 'rm': {df_rm.shape[0]} (and {df_rm.Models_predictions.nunique()} families)\")\n",
    "df_rm.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704836ed-5041-48df-99bd-e5c0ee289bfb",
   "metadata": {},
   "source": [
    "#### Now keep track of the predictions we associated to 'rm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb4767-0e14-4976-b661-3cebd0bb63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_rm(session, predictions):\n",
    "    rm_roles = []\n",
    "    words = session.split(\" \")\n",
    "    predictions = predictions.split(\" -- \")\n",
    "    for word, prediction in zip(words, predictions):\n",
    "        if \"rm\" == word:\n",
    "            rm_roles.append(prediction)\n",
    "    return \" -- \".join(rm_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb2cc6-8a77-4176-9dd2-53345a62012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df_rm[\"rm_roles\"] = df_rm.progress_apply(lambda row: track_rm(row.full_session, row.Models_predictions), axis = 1)\n",
    "df_rm.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb2b090-bb78-4c2b-a6ac-352a6c339ba7",
   "metadata": {},
   "source": [
    "### How many sessions we can associate to each echo's use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d17930-5ce1-4315-950a-c38f3f5c2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_associated_to_use = df_rm.groupby(\"rm_roles\").full_session.count().reset_index(name = \"associated_sessions\")\n",
    "print(f\"There are {sessions_associated_to_use.shape[0]} different uses of the command 'rm'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0808e701-eb4a-4d83-abdd-4f9e8a54b406",
   "metadata": {},
   "source": [
    "### Count how many \"families\" we associated per use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a5af6-db58-426e-810b-7d648a9f1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "families_associated_to_use = df_rm.drop_duplicates(\"Models_predictions\").groupby(\"rm_roles\").Models_predictions.count().reset_index(name = \"associated_families\")\n",
    "sessions_and_families_per_use = sessions_associated_to_use.merge(families_associated_to_use, on = \"rm_roles\")\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(sessions_and_families_per_use.sort_values(by = \"associated_sessions\", ascending = False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76b739-4220-4359-9f76-745e471ce068",
   "metadata": {},
   "source": [
    "#### Show some examples of such usages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a914463c-e801-47ab-ab9b-d6f0a0ff5c0e",
   "metadata": {},
   "source": [
    "##### Idea is to select a family associated to role if:\n",
    "- Family is numerous enough \n",
    "- Family is \"dissimilar\" to the ones observed before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696c4c4-dd6c-4dc6-91f7-77cf54c0c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rm.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e09e5c-24b9-4704-a3ea-07c83940165d",
   "metadata": {},
   "source": [
    "##### Sort previous dataframe according to number of associated sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c07222-cc9f-4a9e-9369-daadbaa975a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_and_families_per_use.sort_values(by = \"associated_sessions\", ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443dba80-cc9d-4780-b290-c51df7932d00",
   "metadata": {},
   "source": [
    "##### Create DF to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5bf2b-8c9f-4807-9f51-6b887e4182ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rm_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cac9c9-a9b9-4d95-84a0-9c34da39fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as lev\n",
    "\n",
    "selected_role = sessions_and_families_per_use.rm_roles.iloc[0]\n",
    "print(f\"For echo roles: {selected_role}\")\n",
    "examples = df_rm[df_rm.rm_roles == selected_role]\n",
    "families_numerosities = examples.groupby(\"Models_predictions\").full_session.count().reset_index(name = \"occurrences\").sort_values(by = \"occurrences\", ascending = False)\n",
    "prev_families = [\"\"]\n",
    "it = 0\n",
    "i = 0\n",
    "while i < 3 and it != families_numerosities.shape[0]: # for the top 3 families\n",
    "    chosen_family = families_numerosities.iloc[it].Models_predictions\n",
    "    nc_prediction = df_rm[df_rm.Models_predictions == chosen_family].Predicted_classes.iloc[0]\n",
    "    occurrences = families_numerosities.iloc[it].occurrences\n",
    "    embedded_family = \"\".join([str(label2id[word]) for word in chosen_family.split(\" -- \")])\n",
    "    flag = True\n",
    "    for prev_family in prev_families: # Check the examples you showed before. Accept new examples if \"dissimilar\" enough\n",
    "        lev_distance = lev(prev_family, embedded_family)\n",
    "        if lev_distance < 5: #At least 5 words must be different\n",
    "            flag = False\n",
    "    if flag:\n",
    "        examples_for_family = examples[examples.Models_predictions == chosen_family][\"full_session\"]\n",
    "        for it in range(np.min([2, examples_for_family.shape[0]])):\n",
    "            full_session = examples_for_family.iloc[it]\n",
    "            colored_sessions = color_sessions(full_session, nc_prediction, chosen_family, \"rm\")\n",
    "            colored_roles = color_roles(chosen_family)\n",
    "            df_rm_results.append((colored_roles, colored_sessions))\n",
    "        prev_families.append(embedded_family)\n",
    "        i += 1\n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5442d0-d456-4b3e-b9aa-46411c51a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as lev\n",
    "\n",
    "selected_role = sessions_and_families_per_use.rm_roles.iloc[2]\n",
    "print(f\"For echo roles: {selected_role}\")\n",
    "examples = df_rm[df_rm.rm_roles == selected_role]\n",
    "families_numerosities = examples.groupby(\"Models_predictions\").full_session.count().reset_index(name = \"occurrences\").sort_values(by = \"occurrences\", ascending = False)\n",
    "prev_families = [\"\"]\n",
    "it = 0\n",
    "i = 0\n",
    "while i < 3 and it != families_numerosities.shape[0]: # for the top 3 families\n",
    "    chosen_family = families_numerosities.iloc[it].Models_predictions\n",
    "    nc_prediction = df_rm[df_rm.Models_predictions == chosen_family].Predicted_classes.iloc[0]\n",
    "    occurrences = families_numerosities.iloc[it].occurrences\n",
    "    embedded_family = \"\".join([str(label2id[word]) for word in chosen_family.split(\" -- \")])\n",
    "    flag = True\n",
    "    for prev_family in prev_families: # Check the examples you showed before. Accept new examples if \"dissimilar\" enough\n",
    "        lev_distance = lev(prev_family, embedded_family)\n",
    "        if lev_distance < 5: #At least 5 words must be different\n",
    "            flag = False\n",
    "    if flag:\n",
    "        examples_for_family = examples[examples.Models_predictions == chosen_family][\"full_session\"]\n",
    "        for it in range(np.min([2, examples_for_family.shape[0]])):\n",
    "            full_session = examples_for_family.iloc[it]\n",
    "            colored_sessions = color_sessions(full_session, nc_prediction, chosen_family, \"rm\")\n",
    "            colored_roles = color_roles(chosen_family)\n",
    "            df_rm_results.append((colored_roles, colored_sessions))\n",
    "        prev_families.append(embedded_family)\n",
    "        i += 1\n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f7624-3991-460f-ae2f-9fddcee4e3e0",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8280015-a322-4017-9786-937c0b3456a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_export = pd.DataFrame(df_rm_results, columns = [\"Sequence of intents\", \"Session\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4112c-38e9-4566-87d3-29f7991ee1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_export.to_html(f\"./Inference_results/1_Stats_per_prediction/rm_study.html\", escape = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b58fbbc-50d5-4671-bbbc-83518f2aad60",
   "metadata": {},
   "source": [
    "## Now, focus on 1 intent (e.g., \"Execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20224bcf-c9cd-4931-873f-8a3fb933dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_df = grouped_df[grouped_df[\"splitted_prediction\"] == \"Execution\"]\n",
    "print(f\"Selected {execution_df.shape[0]} unique tuples (word, 'Execution')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5dbf5-bb06-4445-96da-ef56d6e9a986",
   "metadata": {},
   "source": [
    "##### Visualize some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eaeae6-82c0-408b-b9ec-3a2b52f9d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_df.sort_values(by = \"occurrences_tuple\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eacc45-08a9-4029-93c7-58ff669d1e8b",
   "metadata": {},
   "source": [
    "#### Now some examples in which those words were used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c87a0-573d-4f7e-89b0-1b1e1af6d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_execution_df = unique_corpus[unique_corpus[\"full_session\"].str.contains(\".i\")]\n",
    "print(f\"Selected {example_execution_df.shape[0]} sessions ({example_execution_df.shape[0] / unique_corpus.shape[0] * 100:.2f} % of total)\")\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(example_execution_df[[\"full_session\"]].head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516514f-2db9-40d5-a6d0-b07922bcda3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2edd37-0a41-459e-a969-b2555a40b6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
